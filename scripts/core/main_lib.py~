from sklearn.feature_selection import VarianceThreshold
from skimage.exposure import equalize_adapthist
from skimage.util import view_as_windows, view_as_blocks
from skimage.data import load
from scipy.signal import medfilt
import numpy as np
import matplotlib.image as mpimg
import matplotlib.cm as cm
from skimage.draw import circle_perimeter
import multiprocessing
from sklearn.cluster import MiniBatchKMeans
import csv
import time
import os
from distance.distance import cdist as native_cdist

def select_centroids(centroids):
    
    sel = VarianceThreshold(threshold=np.var(centroids))
    new_centroids = sel.fit_transform(centroids.T)
    new_centroids = new_centroids.T

    return new_centroids


def centroids_to_image(centroids, image_size, rfsize, g=0):
    margin = image_size / rfsize
    horizontal = []
    for i in xrange(margin):
        for j in xrange(margin):
            if j == 0:
                m_img = np.reshape(centroids[i*margin + j,:], (rfsize, rfsize))
            else:
                m_img = np.hstack((m_img, np.reshape(centroids[i*margin + j,:], (rfsize, rfsize))))
        horizontal.append(m_img)

    img = horizontal[0]
    for m_img in horizontal[1:]:
        img = np.vstack((img, m_img))

    mpimg.imsave('centroids_{0}{1}.png'.format(rfsize, g), img, cmap=cm.Greys_r)


def open_csv():
    labels_dict = {0:[], 1:[], 2:[], 3:[], 4:[]}

    with open('/home/jbzik/Documents/Diplomski_Bzik/jbzik_kaggle_data/data/trainLabels.csv','rb') as f:
        reader = csv.reader(f)
        for row in reader:
#            s = row[0].split('\t')
            if row[0] == 'image':
                continue
            else:
                labels_dict[int(row[1])].append(row[0])
    return labels_dict


def extract_patches(path, numPatchesPerImage, patchSize, all=False):
    
    img = load(path)
    img = img[:,:,1]
    img = equalize_adapthist(img)
    windows = view_as_windows(img, (patchSize,patchSize))
    j = 0
    patches = np.zeros((numPatchesPerImage, patchSize*patchSize))
    while(j < numPatchesPerImage):
        
        sx = np.random.randint(0, windows.shape[0] - 1)  
        sy = np.random.randint(0, windows.shape[0] - 1)
        x = (patchSize/2 - 1) + sx
        y = (patchSize/2 - 1) + sy
        r = (img.shape[0]/2) - 1

        if np.sqrt((x - r) ** 2 + (y - r) **2 ) < r:
#            mpimg.imsave('img_patch{0}_approved.png'.format(j), windows[sx, sy, :], cmap=cm.Greys_r)
            patch = windows[sx, sy, :].flatten()            
            patches[j,:] = patch
            j += 1 
        else:
 #           mpimg.imsave('img_patch{0}_declined.png'.format(j), windows[sx, sy, :], cmap=cm.Greys_r)
            if j > 0:
                j -= 1 
    
    return patches


def get_perimeter(img):
    cx = img.shape[0]/2
    cc, rr = circle_perimeter(cx - 1, cx - 1, 256)
    return rr, cc


def extract(rfSize):
    nums = {0:1, 1:5, 2:2, 3:10, 4:10}
    labels_dict = open_csv()

    for j in range(0, 5):
        if j == 0:
            images = labels_dict[j][:10000]

        numOfPatches = nums[j]
        path = '/home/jbzik/Documents/Diplomski_Bzik/jbzik_kaggle_data/data/resized/trainOriginal/'
        #data = np.load('class_{0}.npy'.format(i))

        patches = np.zeros((len(images)*numOfPatches, rfSize*rfSize))
        
        pool = multiprocessing.Pool(multiprocessing.cpu_count())
        results = [pool.apply_async(extract_patches, args=(path + images[i] + '.jpeg', numOfPatches, rfSize,)) for i in xrange(len(images))]
        

        for i in xrange(len(images)):
            patches[i*numOfPatches: (i*numOfPatches) + numOfPatches,:] = np.array(results[i].get())

            if i % 10000 == 0:
                print "Extracting {0}/{1} patch".format(i*nums[j], nums[j]*len(images))

        print "Finished"
        patches = patches[~np.isnan(patches).any(axis=1)]
        
        np.save('core/patches_{0}_{1}.npy'.format(j, rfSize), patches)


#@profile
def kmeans(rfsize):
    import os
    print os.getcwd()
    patches0 = np.load('core/patches_0_{0}.npy'.format(rfsize))
    patches1 = np.load('core/patches_1_{0}.npy'.format(rfsize))
    patches = np.vstack((patches0, patches1))
    patches0 = np.load('core/patches_2_{0}.npy'.format(rfsize))
    patches1 = np.load('core/patches_3_{0}.npy'.format(rfsize))
    patches = np.vstack((patches, patches0, patches1))
    del patches1
    patches0 = np.load('core/patches_4_{0}.npy'.format(rfsize))
    patches = np.vstack((patches, patches0))
    del patches0
    print "Patches ucitani"
    
    
    patchesMean = np.mean(patches, axis=1, dtype=np.float32, keepdims=True)
    patchesVar = np.var(patches, axis=1, dtype=np.float32, keepdims=True)
    offsetMatrix = 10.0 * np.ones(patchesVar.shape)
    patches = (patches - patchesMean) / np.sqrt(patchesVar + offsetMatrix)
    del patchesMean, patchesVar, offsetMatrix
    print "Izracunato"

    C = np.cov(patches, y=None, rowvar=0, ddof=1).T
    M = np.mean(patches, axis=0, dtype=np.float32, keepdims=False)
    W, V = np.linalg.eig(C)
    P = np.dot(np.dot(V, np.diag(np.diag(np.sqrt(1./(np.diagflat(W) + 0.1))))), V.T) 

    #M = np.load('train_mean_windowsize.npy')
    #P = np.load('train_eigenvectors_windowsize.npy')
    patches = np.dot((patches - M), P)
    del W, V, C
    print "Whitened"

    np.save('core/train_mean_windowsize', M)
    np.save('core/train_eigenvectors_windowsize', P)
    print patches.shape 
    n_clusters = int(np.sqrt(patches.shape[0]/2))
    estimator = MiniBatchKMeans(n_clusters=n_clusters, verbose=True, batch_size=1000, compute_labels=False)
    estimator.fit(patches)
    print estimator.cluster_centers_.shape
    np.save('core/centroids.npy', estimator.cluster_centers_)

def pool(q):
    return np.array([np.sum(np.sum(q, axis=1), axis=0)])


def pool_quadrant(patches, rooti, rootj, i, j, iz, jw):
    q1 = pool(patches[rooti:rooti+i, rootj:rootj+j, :])
    #q2 = pool(patches[rooti+i:iz, rootj:rootj+j, :])
    q3 = pool(patches[rooti:rooti+i, rootj+j:jw, :])
    #q4 = pool(patches[rooti+i:iz, rootj+j:jw, :])
    
    print q1[q1==0].shape
    print q3[q3==0].shape
    q = np.vstack((q1,q3)).flatten()
    return q


def extract_features_img(path, centroids, rfSize, M, P, stride, normal_pooling=True):
    
    total_start = time.time()
    img = load(path)
    try:
        img = img[:,:,1]
    except:
        return None
    
    img = equalize_adapthist(img)
    numFeats = img.shape[0] * img.shape[1]
    numCentroids = centroids.shape[0]

    windows = view_as_windows(img, (rfSize, rfSize), stride)
    patches = np.reshape(windows, (windows.shape[0]*windows.shape[1], rfSize*rfSize))

    patchesMean = np.mean(patches, axis=1, dtype=np.float32, keepdims=True)
    patchesVar = np.var(patches, axis=1, dtype=np.float32, ddof=1, keepdims=True)
    offsetMatrix = 10.0 * np.ones(patchesVar.shape)
    patches = (patches - patchesMean) / np.sqrt(patchesVar + offsetMatrix)
    
    patches = np.dot((patches - M), P)
    
    #calculate distance from all patches to all centroids
    z = native_cdist(patches, centroids)
    
    #mean distance from each patch to all centtroids
    mu = np.tile(np.array([np.mean(z, axis = 1)]).T, (1, centroids.shape[0]))
    patches = np.maximum(mu - z, np.zeros(mu.shape))

    prows = (img.shape[0] - rfSize + stride)/stride
    pcols = (img.shape[1] - rfSize + stride)/stride
        
    patches = np.reshape(patches, (prows, pcols, numCentroids))
    halfr = np.round(float(prows)/2)
    halfc = np.round(float(pcols)/2)
        
    if normal_pooling:       
        q1 = np.array([np.sum(np.sum(patches[0:halfc, 0:halfr, :], axis = 1),axis = 0)])
        q2 = np.array([np.sum(np.sum(patches[halfc:patches.shape[0], 0:halfr, :], axis = 1),axis = 0)])
        q3 = np.array([np.sum(np.sum(patches[0:halfc, halfr:patches.shape[1], :], axis = 1),axis = 0)])
        q4 = np.array([np.sum(np.sum(patches[halfc:patches.shape[0], halfr:patches.shape[1], :], axis = 1),axis =     0)])
        feature_vector = np.vstack((q1,q2,q3,q4)).flatten()

    else:
        
        quartr = np.round(float(prows)/4)
        quartc = np.round(float(pcols)/2)
        q1 = pool_quadrant(patches, 0, 0, quartc, quartr, halfc, halfr)        
        q2 = pool_quadrant(patches, halfc, 0, quartc, quartr, patches.shape[0], halfr) 
        q3 = pool_quadrant(patches, 0, halfr, quartc, quartr, halfc, patches.shape[1])
        q4 = pool_quadrant(patches, halfc, halfr, quartc, quartr, patches.shape[0], patches.shape[1])
        feature_vector = np.vstack((q1, q2, q3, q4)).flatten()

               
    return feature_vector

    
def extract_features_all(rfSize, stride=False, train=True):
    images_dict = open_csv()
    if train:
        path = '/home/jbzik/Documents/Diplomski_Bzik/jbzik_kaggle_data/data/resized/trainOriginal/'
    else:
#        path = '/home/jbzik/Documents/Diplomski_Bzik/jbzik_kaggle_data/data/resized/testOriginal/'
        path  = '/home/jbzik/Documents/Diplomski_Bzik/jbzik_kaggle_data/data/resized/'
        images = []
        labels = []

        for folder in os.listdir(path):
            if 'train_sm' in folder:
                temp = os.listdir(path + folder)
                images += [path + folder + '/' + c for c in temp if c.split('.')[0] not in images_dict[0]]
        
                for l in temp:
                    label = l.split('.')[0]
                    if label in images_dict[1]:
                        labels.append(1)
                    elif label in images_dict[2]:
                        labels.append(2)
                    elif label in images_dict[3]:
                        labels.append(3)
                    elif label in images_dict[4]:
                        labels.append(4)
    
    if stride:
        stride = stride
    else:
        stride = rfSize/2

    centroids = np.load('core/{0}vs512/centroids16_selected.npy'.format(rfSize))
    M = np.load('core/{0}vs512/train_mean_windowsize.npy'.format(rfSize))
    P = np.load('core/{0}vs512/train_eigenvectors_windowsize.npy'.format(rfSize))
    
    if train:
        numOfExamples = 0
        images = []
        for i in xrange(5):
            numOfExamples += len(images_dict[i])
            images += images_dict[i]
    else:
#        images = os.listdir(path)
        numOfExamples = len(images)
    
    X = np.zeros((numOfExamples, centroids.shape[0]*8))
        
    for i in xrange(len(images)):
        s = time.time()
        if train:
            X[i,:] = extract_features_img(path + images[i] + '.jpeg', centroids, rfSize, M, P, stride, False)
        else:
            print images[i]
            X[i,:] = extract_features_img(images[i], centroids, rfSize, M, P, stride, False)
      

        #print X[i,:]
        print X[i,:].shape
        end = time.time()
        print "Sample {0}/{1}".format(i, len(images))
        print images[i]
        print end - s

    if train: 
        np.save('train_features_{0}_dense.npy'.format(rfSize), X)
    else:
        np.save('additional_features_{0}.npy'.format(rfSize), X)
        np.save('additional_labels.npy', np.array(labels))

def extract_second_layer_centroids(features):
    
    patches = np.zeros((features.shape[0]*100, 100))

    for i in xrange(features.shape[0]):
        for j in xrange(50):
            patch = np.random.choice(features[i,:], 100)
            print patch
            patches[i*50 + j,] = patch
            print "{0}/{1}".format(i*50+j, features.shape[0]*50) 
    
    patchesMean = np.mean(patches, axis=1, dtype=np.float32, keepdims=True)
    patchesVar = np.var(patches, axis=1, dtype=np.float32, ddof=1, keepdims=True)
    offsetMatrix = 10.0 * np.ones(patchesVar.shape)
    patches = (patches - patchesMean) / np.sqrt(patchesVar + offsetMatrix)

    numCentroids = int(np.sqrt(patches.shape[0]/2))
    estimator = MiniBatchKMeans(numCentroids, verbose=True, batch_size=1000, compute_labels=False)
    patches = patches[~np.isnan(patches).any(axis=1)]
    estimator.fit(patches)


    np.save('second_layer_centroids.npy', estimator.cluster_centers_)

def exfs(centroids, features):
   
    s_features = np.zeros((features.shape[0], 4*centroids.shape[0]))
    print centroids.shape
    from time import sleep
    sleep(3)
    for i in xrange(features.shape[0]):
        start = time.time()
        
        patches = np.zeros((features.shape[1]/100 + 1, 100))
        for j in range(0, features.shape[1], 100):
            if features[i, j:j+100].shape[0] == 100:
                patches[j/100,:] = features[i, j:j+100]
                
        patchesMean = np.mean(patches, axis=1, dtype=np.float32, keepdims=True)
        patchesVar = np.var(patches, axis=1, dtype=np.float32, keepdims=True)
        offsetMatrix = 10.0 * np.ones(patchesVar.shape)
        patches = (patches - patchesMean) / np.sqrt(patchesVar + offsetMatrix)

        z = native_cdist(patches, centroids)
        
        mu = np.tile(np.array([np.mean(z, axis = 1)]).T, (1, centroids.shape[0]))
        patches = np.maximum(mu - z, np.zeros(mu.shape))
        
        q = patches.shape[0]/4
        q1 = np.sum(patches[0:q,:], axis=0)       

        q_all = q1
        for j in range(1,4):
            q_all = np.hstack((q_all,np.sum(patches[j*q:(j+1)*q,:], axis=0)))

        s_features[i,:] = q_all
        end = time.time()
        if i % 1000 == 0:
            print "{0}/{1}".format(i, features.shape[0])

    np.save('second_layer_additional_features.npy', s_features)

def calc_entropy(img):
    from matplotlib.pylab import hist
    from scipy.stats import entropy
    hist, bins = np.histogram(img.ravel(), 256, [0,256])
    distribution = hist.astype(np.float32)/bins.shape[0]
    return entropy(distribution)

def cluster_images():
    path = '/home/jbzik/Documents/Diplomski_Bzik/jbzik_kaggle_data/data/resized/trainOriginal/'
    dir = os.listdir(path)
    images = np.zeros((len(dir), 3))
    names = []

    for i, imgname in enumerate(dir):
#        img = load(path + imgname)
#        images[i, 0] = np.mean(img)
#        images[i, 1] = np.var(img)
#        images[i, 2] = calc_entropy(img)
#        print str(i) + "/" + str(len(dir))
        names.append(imgname)

#    estimator = MiniBatchKMeans(n_clusters=10, verbose=True, batch_size=1000)
#    estimator.fit(images)
#    from sklearn.externals import joblib
#    joblib.dump(estimator, 'estimator.pkl')
#    np.save('data.npy', images)
    
    with open('names.txt', 'wb') as f:
        for name in names:
            f.write(name + '\n')
    


if __name__ == '__main__':
    #extract_features_all(64, False)
    #extract_features_all(32, False)
    #extract_features_all(16, 6, False)
    #extract_features_all(8, False)
    #extract_second_layer_features(np.load('16vs512features/train_features_16_selected_dense.npy'))
    exfs(np.load('16vs512features/second_layer_centroids.npy'), np.load('additional_features_16.npy'))
    #cluster_images()
